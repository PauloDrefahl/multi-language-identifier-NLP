# -*- coding: utf-8 -*-
"""LanguageIdentifier.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1g2FHaqCJsc3_xx_-98OhRKkHE3kUzFk9

#Project 2 - Paulo Drefahl: Multi-language Identifier
The project aims to develop a language identification model capable of distinguishing texts in differeent languages from a multilingual dataset.The model will predict the language of a given text based on its features and contextual patterns.
"""

#!pip install transformers
#!pip install datasets
#!pip install simpletransformers
#!pip install evaluate
#!pip install scikit-learn

"""#Loading Libraries and Datasets"""

from simpletransformers.classification import ClassificationModel
import pandas as pd
from datasets import load_dataset

datasetTrain = load_dataset("CohereForAI/aya_collection", "aya_dataset")
datasetTest = load_dataset("papluca/language-identification")

aya_dataset = datasetTrain["train"]
papluca_dataset = datasetTest["test"]

"""#Raw datasets
Printing datasets before formatting them.

"""

fracDataSetTrain = aya_dataset.select(range(20))
fracDataSetTest = papluca_dataset.select(range(20))

print("Raw First database:")
print(fracDataSetTrain.to_pandas())
print("Raw Second database:")
print(fracDataSetTest.to_pandas())

"""#Formatting Data
Adjusting the number of records, collumns of interrest, renaming them to match and change their position for better visualization
"""

df = fracDataSetTrain.to_pandas()[['inputs', 'language']]
df2 = fracDataSetTest.to_pandas()[['text', 'labels']]
df2.rename(columns={'text': 'inputs', 'labels': 'language'}, inplace=True)

print("First database (aya_collection):")
print(df)
print("\nSecond database (language-identification):")
print(df2)

"""#Filtering Languages and Mapping them to be Trained"""

from simpletransformers.classification import ClassificationModel
import pandas as pd
from datasets import load_dataset
from sklearn.metrics import classification_report

datasetTrain = load_dataset("CohereForAI/aya_collection", "aya_dataset")
datasetTest = load_dataset("papluca/language-identification")

aya_dataset = datasetTrain["train"]
papluca_dataset = datasetTest["test"]

fracDataSetTrain = aya_dataset.select(range(5000))
fracDataSetTest = papluca_dataset.select(range(5000))

df = fracDataSetTrain.to_pandas()[['inputs', 'language']]
df2 = fracDataSetTest.to_pandas()[['text', 'labels']]
df2.rename(columns={'text': 'inputs', 'labels': 'language'}, inplace=True)

allowed_languages1 = ["por", "eng", "fra", "jpn", "spa", "ita", "deu"]
df = df[df['language'].isin(allowed_languages1)]

allowed_languages1 = ["pt", "en", "fr", "ja", "es", "it", "de"]
df2 = df2[df2['language'].isin(allowed_languages1)]

language_mapping = {
    "por": 0, "eng": 1, "fra": 2, "jpn": 3, "spa": 4, "ita": 5, "deu": 6,
    "pt": 0, "en": 1, "fr": 2, "ja": 3, "es": 4, "it": 5, "de": 6
}

# Map languages to numbers
df['language'] = df['language'].map(language_mapping)
df2['language'] = df2['language'].map(language_mapping)

print(df2.info())

print(df)
print("\n","-"*80,"\n")
print(df2)

"""#Training roBERTa with First Dataset"""

model = ClassificationModel(
    "roberta",
    "roberta-base",
    num_labels=7,
    use_cuda=False,
    args={"reprocess_input_data": True, "overwrite_output_dir": True},
)

model.train_model(df, text_column="inputs", label_column="language")

"""# training Bert Uncased"""

model_bert = ClassificationModel(
    "bert",
    "bert-base-uncased",
    num_labels=7,
    use_cuda=False,
    args={"reprocess_input_data": True, "overwrite_output_dir": True},
)

model_bert.train_model(df, text_column="inputs", label_column="language")

"""#Training Distilbert uncased"""

model_distilbert = ClassificationModel(
    "distilbert",
    "distilbert-base-uncased",
    num_labels=7,
    use_cuda=False,
    args={"reprocess_input_data": True, "overwrite_output_dir": True},
)

model_distilbert.train_model(df, text_column="inputs", label_column="language")



"""#Testing trained roBERTa

"""

from sklearn.metrics import accuracy_score, precision_score, recall_score

predictions_roberta, _ = model.predict(df2['inputs'].tolist())
y_true = df2['language']

accuracy_roberta = accuracy_score(y_true, predictions_roberta)
precision_roberta = precision_score(y_true, predictions_roberta, average='weighted')
recall_roberta = recall_score(y_true, predictions_roberta, average='weighted')

print("RoBERTa Metrics:")
print("Accuracy:", accuracy_roberta)
print("Precision:", precision_roberta)
print("Recall:", recall_roberta)
print()

"""#Testing BERT"""

predictions_bert, _ = model_bert.predict(df2['inputs'].tolist())
accuracy_bert = accuracy_score(y_true, predictions_bert)
precision_bert = precision_score(y_true, predictions_bert, average='weighted')
recall_bert = recall_score(y_true, predictions_bert, average='weighted')

print("BERT Metrics:")
print("Accuracy:", accuracy_bert)
print("Precision:", precision_bert)
print("Recall:", recall_bert)
print()

"""#Testing distilBERT"""

predictions_distilbert, _ = model_distilbert.predict(df2['inputs'].tolist())
accuracy_distilbert = accuracy_score(y_true, predictions_distilbert)
precision_distilbert = precision_score(y_true, predictions_distilbert, average='weighted')
recall_distilbert = recall_score(y_true, predictions_distilbert, average='weighted')

print("DistilBERT Metrics:")
print("Accuracy:", accuracy_distilbert)
print("Precision:", precision_distilbert)
print("Recall:", recall_distilbert)
print()

"""# Metric: Precision, Recall, f1-score, support"""

from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score
import seaborn as sns
import matplotlib.pyplot as plt

# Data for the three models
models = ['RoBERTa', 'BERT', 'DistilBERT']
accuracies = [accuracy_roberta, accuracy_bert, accuracy_distilbert]
precisions = [precision_roberta, precision_bert, precision_distilbert]
recalls = [recall_roberta, recall_bert, recall_distilbert]

# Calculate F1 scores
f1_scores = [2 * (p * r) / (p + r) for p, r in zip(precisions, recalls)]

# Plotting the metrics
fig, ax = plt.subplots(1, 4, figsize=(20, 6))

# Accuracy
ax[0].bar(models, accuracies, color='skyblue')
ax[0].set_title('Accuracy')
ax[0].set_ylim(0, 1)

# Precision
ax[1].bar(models, precisions, color='salmon')
ax[1].set_title('Precision')
ax[1].set_ylim(0, 1)

# Recall
ax[2].bar(models, recalls, color='lightgreen')
ax[2].set_title('Recall')
ax[2].set_ylim(0, 1)

# F1 Score
ax[3].bar(models, f1_scores, color='gold')
ax[3].set_title('F1 Score')
ax[3].set_ylim(0, 1)

# Adding labels
for i in range(4):
    ax[i].set_ylabel('Score')
    ax[i].set_xlabel('Model')
    ax[i].grid(axis='y', linestyle='--', alpha=0.6)

plt.tight_layout()
plt.show()

"""# Metrics: Confusion Matrix"""

from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

inverse_language_mapping = {
    0: "por",
    1: "eng",
    2: "fra",
    3: "jpn",
    4: "spa",
    5: "ita",
    6: "deu"
}

def convert_labels_to_lang(labels):
    return [inverse_language_mapping[label] for label in labels]

y_true_lang = convert_labels_to_lang(y_true)

predictions_roberta_lang = convert_labels_to_lang(predictions_roberta)
predictions_bert_lang = convert_labels_to_lang(predictions_bert)
predictions_distilbert_lang = convert_labels_to_lang(predictions_distilbert)

conf_matrix_roberta = confusion_matrix(y_true_lang, predictions_roberta_lang)
plt.figure(figsize=(12, 8))
sns.heatmap(conf_matrix_roberta, annot=True, fmt='', cmap='viridis', xticklabels=sorted(inverse_language_mapping.values()), yticklabels=sorted(inverse_language_mapping.values()))
plt.title('RoBERTa Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

conf_matrix_bert = confusion_matrix(y_true_lang, predictions_bert_lang)
plt.figure(figsize=(12, 8))
sns.heatmap(conf_matrix_bert, annot=True, fmt='', cmap='viridis', xticklabels=sorted(inverse_language_mapping.values()), yticklabels=sorted(inverse_language_mapping.values()))
plt.title('BERT Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

conf_matrix_distilbert = confusion_matrix(y_true_lang, predictions_distilbert_lang)
plt.figure(figsize=(12, 8))
sns.heatmap(conf_matrix_distilbert, annot=True, fmt='', cmap='viridis', xticklabels=sorted(inverse_language_mapping.values()), yticklabels=sorted(inverse_language_mapping.values()))
plt.title('DistilBERT Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

"""#Installing OpenAI for review"""

#!pip install openai

"""#Analyzing Results with chatgpts API"""

from openai import OpenAI


prompt = f"""
Given the evaluation metrics for three models (RoBERTa, BERT, and DistilBERT) on a language classification task,
let's analyze the performance of each model:

RoBERTa Metrics:
Accuracy: {accuracy_roberta}
Precision: {precision_roberta}
Recall: {recall_roberta}

BERT Metrics:
Accuracy: {accuracy_bert}
Precision: {precision_bert}
Recall: {recall_bert}

DistilBERT Metrics:
Accuracy: {accuracy_distilbert}
Precision: {precision_distilbert}
Recall: {recall_distilbert}

Based on these metrics, which model performed the best overall and why?
"""

client = OpenAI(api_key='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')
#Dr. Koufakou, after a week I will remove this api key from the project. If the key is not there you can let me know and I will add it again so you can run it.

completion = client.chat.completions.create(
  model="gpt-3.5-turbo",
  messages=[
    {"role": "system", "content": "Given the evaluation metrics for three models (RoBERTa, BERT, and DistilBERT) on a language classification task, let's analyze the performance of each model:"},
    {"role": "user", "content": f"{prompt}"}
  ]
)

print(completion.choices[0].message.content)

"""#Conclusion
RoBERTa performed the best overall, although it struggled slightly with Portuguese and Italian.
DistilBERT performed closely to RoBERTa but had more issues with English and German.
BERT underperformed compared to the other two models.
RoBERTa had confusion primarily between Portuguese and Italian, and to a lesser extent between Spanish and Italian, and Portuguese and Spanish.
DistilBERT had more problems with English and German, in addition to similar issues with Spanish, Italian, and Portuguese as RoBERTa.
Languages with similar origin can be harder to distinguish depending on the model and the language itself. (english -> deutsch, portuguese -> spanish -> italian )

"""